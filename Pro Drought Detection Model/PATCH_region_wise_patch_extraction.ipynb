{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85dbd900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 363MB\n",
      "Dimensions:              (time: 300, lat: 197, lon: 128)\n",
      "Coordinates:\n",
      "  * lat                  (lat) float64 2kB -28.95 -28.9 -28.85 ... -19.2 -19.15\n",
      "  * lon                  (lon) float64 1kB 146.0 146.1 146.1 ... 152.3 152.3\n",
      "  * time                 (time) datetime64[ns] 2kB 2000-01-01 ... 2024-12-01\n",
      "Data variables:\n",
      "    monthly_rain         (time, lat, lon) float64 61MB ...\n",
      "    max_temp             (time, lat, lon) float64 61MB ...\n",
      "    min_temp             (time, lat, lon) float64 61MB ...\n",
      "    radiation            (time, lat, lon) float64 61MB ...\n",
      "    spi_1                (time, lat, lon) float64 61MB ...\n",
      "    consecutive_drought  (time, lat, lon) float64 61MB ...\n",
      "Attributes:\n",
      "    long_name:     Monthly rainfall\n",
      "    units:         mm\n",
      "    valid_min:     -32765\n",
      "    valid_max:     32767\n",
      "    grid_mapping:  spatial_ref\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset(r\"data\\raw\\BRB_Combined_Consecutive.nc\")\n",
    "print(ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8791348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "\n",
    "# Directories\n",
    "RAW_DATA_DIR = r\"data\\raw\"\n",
    "PATCHES_DIR = r\"data\\patches\"\n",
    "PATCH_SIZE = 32\n",
    "STRIDE = 16\n",
    "\n",
    "# Ensure patch directory exists\n",
    "os.makedirs(PATCHES_DIR, exist_ok=True)\n",
    "\n",
    "def extract_patches(region_file):\n",
    "    # Load region data\n",
    "    ds = xr.open_dataset(os.path.join(RAW_DATA_DIR, region_file))\n",
    "    region_name = region_file.split(\"_Combined_Consecutive.nc\")[0]\n",
    "    region_dir = os.path.join(PATCHES_DIR, region_name)\n",
    "    os.makedirs(region_dir, exist_ok=True)\n",
    "\n",
    "    # Extract variables\n",
    "    variables = [\"monthly_rain\", \"max_temp\", \"min_temp\", \"radiation\", \"spi_1\", \"consecutive_drought\"]\n",
    "    data = np.stack([ds[var].values for var in variables], axis=-1)\n",
    "\n",
    "    lat_size, lon_size, _ = data.shape\n",
    "\n",
    "    # Patch extraction\n",
    "    for lat in range(0, lat_size - PATCH_SIZE + 1, STRIDE):\n",
    "        for lon in range(0, lon_size - PATCH_SIZE + 1, STRIDE):\n",
    "            patch = data[lat:lat + PATCH_SIZE, lon:lon + PATCH_SIZE, :]\n",
    "\n",
    "            # Handle small patches with padding\n",
    "            if patch.shape[0] < PATCH_SIZE or patch.shape[1] < PATCH_SIZE:\n",
    "                padded_patch = np.zeros((PATCH_SIZE, PATCH_SIZE, patch.shape[2]))\n",
    "                padded_patch[:patch.shape[0], :patch.shape[1], :] = patch\n",
    "                patch = padded_patch\n",
    "\n",
    "            # Extract label using mode of consecutive_drought\n",
    "            label_patch = patch[:, :, -1]  # consecutive_drought\n",
    "            patch_label = stats.mode(label_patch.flatten(), keepdims=False).mode\n",
    "\n",
    "            # Save patch and label\n",
    "            patch_filename = f\"{region_name}_{lat}_{lon}.npy\"\n",
    "            label_filename = f\"{region_name}_{lat}_{lon}_label.npy\"\n",
    "\n",
    "            np.save(os.path.join(region_dir, patch_filename), patch)\n",
    "            np.save(os.path.join(region_dir, label_filename), patch_label)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process each region\n",
    "    for file in os.listdir(RAW_DATA_DIR):\n",
    "        if file.endswith(\"_Combined_Consecutive.nc\"):\n",
    "            print(f\"Processing {file}...\")\n",
    "            extract_patches(file)\n",
    "            print(f\"Finished processing {file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accd41b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BRB_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing BRB_Combined_Consecutive.nc.\n",
      "Processing CHC_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing CHC_Combined_Consecutive.nc.\n",
      "Processing CQC_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing CQC_Combined_Consecutive.nc.\n",
      "Processing CYP_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing CYP_Combined_Consecutive.nc.\n",
      "Processing DEU_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing DEU_Combined_Consecutive.nc.\n",
      "Processing EIU_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing EIU_Combined_Consecutive.nc.\n",
      "Processing GUP_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing GUP_Combined_Consecutive.nc.\n",
      "Processing MGD_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing MGD_Combined_Consecutive.nc.\n",
      "Processing MUL_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing MUL_Combined_Consecutive.nc.\n",
      "Processing NET_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing NET_Combined_Consecutive.nc.\n",
      "Processing NWH_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing NWH_Combined_Consecutive.nc.\n",
      "Processing SEQ_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing SEQ_Combined_Consecutive.nc.\n",
      "Processing WET_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_18780\\1867924367.py:26: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing WET_Combined_Consecutive.nc.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "\n",
    "# Directories\n",
    "RAW_DATA_DIR = r\"data\\raw\"\n",
    "PATCHES_DIR = r\"data\\patches\"\n",
    "PATCH_SIZE = 32\n",
    "STRIDE = 16\n",
    "\n",
    "# Ensure patch directory exists\n",
    "os.makedirs(PATCHES_DIR, exist_ok=True)\n",
    "\n",
    "def extract_patches(region_file):\n",
    "    # Load region data\n",
    "    ds = xr.open_dataset(os.path.join(RAW_DATA_DIR, region_file))\n",
    "    region_name = region_file.split(\"_Combined_Consecutive.nc\")[0]\n",
    "    region_dir = os.path.join(PATCHES_DIR, region_name)\n",
    "    os.makedirs(region_dir, exist_ok=True)\n",
    "\n",
    "    # Extract variables\n",
    "    variables = [\"monthly_rain\", \"max_temp\", \"min_temp\", \"radiation\", \"spi_1\", \"consecutive_drought\"]\n",
    "\n",
    "    # Iterate over each time step\n",
    "    for time in range(ds.dims['time']):\n",
    "        stacked_data = [ds[var].isel(time=time).values for var in variables]\n",
    "        data = np.stack(stacked_data, axis=-1)\n",
    "\n",
    "        lat_size, lon_size = data.shape[0], data.shape[1]\n",
    "\n",
    "        # Patch extraction\n",
    "        for lat in range(0, lat_size - PATCH_SIZE + 1, STRIDE):\n",
    "            for lon in range(0, lon_size - PATCH_SIZE + 1, STRIDE):\n",
    "                patch = data[lat:lat + PATCH_SIZE, lon:lon + PATCH_SIZE, :]\n",
    "\n",
    "                # Handle small patches with padding\n",
    "                if patch.shape[0] < PATCH_SIZE or patch.shape[1] < PATCH_SIZE:\n",
    "                    padded_patch = np.zeros((PATCH_SIZE, PATCH_SIZE, patch.shape[2]))\n",
    "                    padded_patch[:patch.shape[0], :patch.shape[1], :] = patch\n",
    "                    patch = padded_patch\n",
    "\n",
    "                # Extract label using mode of consecutive_drought\n",
    "                label_patch = patch[:, :, -1]  # consecutive_drought\n",
    "                patch_label = stats.mode(label_patch.flatten(), keepdims=False).mode\n",
    "\n",
    "                # Save patch and label\n",
    "                patch_filename = f\"{region_name}_t{time}_{lat}_{lon}.npy\"\n",
    "                label_filename = f\"{region_name}_t{time}_{lat}_{lon}_label.npy\"\n",
    "\n",
    "                np.save(os.path.join(region_dir, patch_filename), patch)\n",
    "                np.save(os.path.join(region_dir, label_filename), patch_label)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process each region\n",
    "    for file in os.listdir(RAW_DATA_DIR):\n",
    "        if file.endswith(\"_Combined_Consecutive.nc\"):\n",
    "            print(f\"Processing {file}...\")\n",
    "            extract_patches(file)\n",
    "            print(f\"Finished processing {file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47e16e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing BRB_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRB: Total Patches = 31200, Valid Patches = 31200\n",
      "Finished processing BRB_Combined_Consecutive.nc.\n",
      "Processing CHC_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHC: Total Patches = 21600, Valid Patches = 21600\n",
      "Finished processing CHC_Combined_Consecutive.nc.\n",
      "Processing CQC_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CQC: Total Patches = 4800, Valid Patches = 4800\n",
      "Finished processing CQC_Combined_Consecutive.nc.\n",
      "Processing CYP_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CYP: Total Patches = 12000, Valid Patches = 12000\n",
      "Finished processing CYP_Combined_Consecutive.nc.\n",
      "Processing DEU_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEU: Total Patches = 5400, Valid Patches = 5400\n",
      "Finished processing DEU_Combined_Consecutive.nc.\n",
      "Processing EIU_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EIU: Total Patches = 14700, Valid Patches = 14700\n",
      "Finished processing EIU_Combined_Consecutive.nc.\n",
      "Processing GUP_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GUP: Total Patches = 24300, Valid Patches = 24300\n",
      "Finished processing GUP_Combined_Consecutive.nc.\n",
      "Processing MGD_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MGD: Total Patches = 36000, Valid Patches = 36000\n",
      "Finished processing MGD_Combined_Consecutive.nc.\n",
      "Processing MUL_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUL: Total Patches = 16200, Valid Patches = 16200\n",
      "Finished processing MUL_Combined_Consecutive.nc.\n",
      "Processing NET_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET: Total Patches = 1200, Valid Patches = 1200\n",
      "Finished processing NET_Combined_Consecutive.nc.\n",
      "Processing NWH_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWH: Total Patches = 8400, Valid Patches = 8400\n",
      "Finished processing NWH_Combined_Consecutive.nc.\n",
      "Processing SEQ_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEQ: Total Patches = 8400, Valid Patches = 8400\n",
      "Finished processing SEQ_Combined_Consecutive.nc.\n",
      "Processing WET_Combined_Consecutive.nc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jspch\\AppData\\Local\\Temp\\ipykernel_11124\\370587259.py:28: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  for time in range(ds.dims['time']):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WET: Total Patches = 4500, Valid Patches = 4500\n",
      "Finished processing WET_Combined_Consecutive.nc.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "\n",
    "# Directories\n",
    "RAW_DATA_DIR = r\"data\\raw\"\n",
    "PATCHES_DIR = r\"data\\patches with padding_v02\"\n",
    "PATCH_SIZE = 32\n",
    "STRIDE = 16\n",
    "\n",
    "# Ensure patch directory exists\n",
    "os.makedirs(PATCHES_DIR, exist_ok=True)\n",
    "\n",
    "# Patch Extraction with NaN Handling\n",
    "def extract_patches(region_file):\n",
    "    # Load region data\n",
    "    ds = xr.open_dataset(os.path.join(RAW_DATA_DIR, region_file))\n",
    "    region_name = region_file.split(\"_Combined_Consecutive.nc\")[0]\n",
    "    region_dir = os.path.join(PATCHES_DIR, region_name)\n",
    "    os.makedirs(region_dir, exist_ok=True)\n",
    "\n",
    "    # Extract variables\n",
    "    variables = [\"monthly_rain\", \"max_temp\", \"min_temp\", \"radiation\", \"spi_1\", \"consecutive_drought\"]\n",
    "    total_patches, valid_patches = 0, 0\n",
    "\n",
    "    # Iterate over each time step\n",
    "    for time in range(ds.dims['time']):\n",
    "        stacked_data = [ds[var].isel(time=time).values for var in variables]\n",
    "        data = np.stack(stacked_data, axis=-1)\n",
    "\n",
    "        lat_size, lon_size = data.shape[0], data.shape[1]\n",
    "\n",
    "        # Patch extraction\n",
    "        for lat in range(0, lat_size, STRIDE):\n",
    "            for lon in range(0, lon_size, STRIDE):\n",
    "                patch = data[lat:lat + PATCH_SIZE, lon:lon + PATCH_SIZE, :]\n",
    "\n",
    "                # Ensure patch is 32x32 with padding\n",
    "                padded_patch = np.zeros((PATCH_SIZE, PATCH_SIZE, patch.shape[2]))\n",
    "                padded_patch[:patch.shape[0], :patch.shape[1], :] = np.nan_to_num(patch, nan=0.0)  # Replace NaNs with 0\n",
    "\n",
    "                # Calculate label (mode of non-NaN values)\n",
    "                label_patch = padded_patch[:, :, -1]  # consecutive_drought\n",
    "                label_patch = label_patch[~np.isnan(label_patch)]  # Remove NaNs\n",
    "\n",
    "                if len(label_patch) == 0:  # Skip if all are NaN\n",
    "                    continue\n",
    "\n",
    "                patch_label = stats.mode(label_patch.flatten(), keepdims=False).mode\n",
    "\n",
    "                # Save only valid patches\n",
    "                if not np.isnan(patch_label):\n",
    "                    patch_filename = f\"{region_name}_t{time}_{lat}_{lon}.npy\"\n",
    "                    label_filename = f\"{region_name}_t{time}_{lat}_{lon}_label.npy\"\n",
    "                    np.save(os.path.join(region_dir, patch_filename), padded_patch)\n",
    "                    np.save(os.path.join(region_dir, label_filename), patch_label)\n",
    "                    valid_patches += 1\n",
    "\n",
    "                total_patches += 1\n",
    "\n",
    "    print(f\"{region_name}: Total Patches = {total_patches}, Valid Patches = {valid_patches}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process each region\n",
    "    for file in os.listdir(RAW_DATA_DIR):\n",
    "        if file.endswith(\"_Combined_Consecutive.nc\"):\n",
    "            print(f\"Processing {file}...\")\n",
    "            extract_patches(file)\n",
    "            print(f\"Finished processing {file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea42141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Directories\n",
    "RAW_DATA_DIR = r\"data\\raw\"\n",
    "PATCHES_DIR = r\"data\\patches\"\n",
    "PATCH_SIZE = 32\n",
    "STRIDE = 16\n",
    "\n",
    "# Ensure patch directory exists\n",
    "os.makedirs(PATCHES_DIR, exist_ok=True)\n",
    "\n",
    "# Patch Extraction with NaN Handling and Label Distribution Plotting\n",
    "def extract_patches(region_file):\n",
    "    # Load region data\n",
    "    ds = xr.open_dataset(os.path.join(RAW_DATA_DIR, region_file))\n",
    "    region_name = region_file.split(\"_Combined_Consecutive.nc\")[0]\n",
    "    region_dir = os.path.join(PATCHES_DIR, region_name)\n",
    "    os.makedirs(region_dir, exist_ok=True)\n",
    "\n",
    "    # Extract variables\n",
    "    variables = [\"monthly_rain\", \"max_temp\", \"min_temp\", \"radiation\", \"spi_1\", \"consecutive_drought\"]\n",
    "    total_patches, valid_patches = 0, 0\n",
    "    label_distribution = []\n",
    "\n",
    "    # Iterate over each time step\n",
    "    for time in range(ds.dims['time']):\n",
    "        stacked_data = [ds[var].isel(time=time).values for var in variables]\n",
    "        data = np.stack(stacked_data, axis=-1)\n",
    "\n",
    "        lat_size, lon_size = data.shape[0], data.shape[1]\n",
    "\n",
    "        # Patch extraction\n",
    "        for lat in range(0, lat_size, STRIDE):\n",
    "            for lon in range(0, lon_size, STRIDE):\n",
    "                patch = data[lat:lat + PATCH_SIZE, lon:lon + PATCH_SIZE, :]\n",
    "\n",
    "                # Ensure patch is 32x32 with padding\n",
    "                padded_patch = np.zeros((PATCH_SIZE, PATCH_SIZE, patch.shape[2]))\n",
    "                padded_patch[:patch.shape[0], :patch.shape[1], :] = np.nan_to_num(patch, nan=0.0)\n",
    "\n",
    "                # Calculate label (mode of non-NaN values)\n",
    "                label_patch = padded_patch[:, :, -1]  # consecutive_drought\n",
    "                label_patch = label_patch[~np.isnan(label_patch)]  # Remove NaNs\n",
    "\n",
    "                if len(label_patch) == 0:  # Skip if all are NaN\n",
    "                    continue\n",
    "\n",
    "                patch_label = stats.mode(label_patch.flatten(), keepdims=False).mode\n",
    "\n",
    "                # Save only valid patches\n",
    "                if not np.isnan(patch_label):\n",
    "                    patch_filename = f\"{region_name}_t{time}_{lat}_{lon}.npy\"\n",
    "                    label_filename = f\"{region_name}_t{time}_{lat}_{lon}_label.npy\"\n",
    "                    np.save(os.path.join(region_dir, patch_filename), padded_patch)\n",
    "                    np.save(os.path.join(region_dir, label_filename), patch_label)\n",
    "                    valid_patches += 1\n",
    "                    label_distribution.append(patch_label)\n",
    "\n",
    "                total_patches += 1\n",
    "\n",
    "    # Plotting Label Distribution\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(label_distribution, bins=3, edgecolor='black')\n",
    "    plt.title(f\"Label Distribution for {region_name}\")\n",
    "    plt.xlabel(\"Label (0 = No Drought, 1 = Consecutive Drought)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"{region_name}: Total Patches = {total_patches}, Valid Patches = {valid_patches}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Process each region\n",
    "    for file in os.listdir(RAW_DATA_DIR):\n",
    "        if file.endswith(\"_Combined_Consecutive.nc\"):\n",
    "            print(f\"Processing {file}...\")\n",
    "            extract_patches(file)\n",
    "            print(f\"Finished processing {file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-cdmodel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
